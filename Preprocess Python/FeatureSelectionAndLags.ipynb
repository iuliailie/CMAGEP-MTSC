{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "allDirs=[x[0] for x in os.walk('/Users/iuliailie/UCD/mtsdata (2)/')]\n",
    "len(allDirs)\n",
    "allDirs\n",
    "for lagsPermitted in [10, 15, 20]:#file save is repeated for all the number of lags desired\n",
    "   # allDirs=['NetFlow','ECG','Wafer','CMUsubject16','KickvsPunch','WalkvsRun'] \n",
    "     #problem names can be obtained from directory\n",
    "    for i in range(0,len(allDirs)):\n",
    "        dirName=allDirs[i].split('/')[-1]\n",
    "        pandaMTSC_train=pd.read_csv('/Users/iulia/UCD laptop backup/UCD/mtsdata (2)/'+dirName+'/'+dirName+'train.txt',sep='\\t',header=None)\n",
    "        pandaMTSC_test=pd.read_csv('/Users/iulia/UCD laptop backup/UCD/mtsdata (2)/'+dirName+'/'+dirName+'test.txt',sep='\\t',header=None)\n",
    "        print(dirName)\n",
    "        #obtain class flags\n",
    "        uniqClasses=pandaMTSC_train[pandaMTSC_train.columns[-2]].unique()\n",
    "       #train here is given by all features in train file\n",
    "        XVert=pandaMTSC_train[pandaMTSC_train.columns[0:-2]]\n",
    "        #Y here is the class flag\n",
    "        YVert=pandaMTSC_train[pandaMTSC_train.columns[-2]]\n",
    "\n",
    "        # Class trees for target feature determination\n",
    "        \n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        from sklearn.datasets import make_classification\n",
    "        from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "        # Build a classification task using n informative features\n",
    "\n",
    "\n",
    "        # Build a forest and compute the feature importances\n",
    "        forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                                      random_state=0)\n",
    "        X=XVert\n",
    "        y=YVert\n",
    "        forest.fit(X, y)\n",
    "        \n",
    "        #obtained forest fit and important features\n",
    "        importances = forest.feature_importances_\n",
    "        std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                     axis=0)\n",
    "        #sort by importance\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        #most important is assigned as target\n",
    "        target_index=indices[0]\n",
    "        #all others become candidate regression features\n",
    "        dependent_indices=[]\n",
    "        for i in range(1,len(indices)):\n",
    "            dependent_indices.append(indices[i])\n",
    "        dependent_indices.sort()\n",
    "\n",
    "\n",
    "        #obtaining all time series in train file\n",
    "        ts_indices=pandaMTSC_train[pandaMTSC_train.columns[-1]].unique()\n",
    "\n",
    "        pandaMTSCLags_train=pd.DataFrame([])\n",
    "        pandaMTSC_train.shape[1]\n",
    "\n",
    "        \n",
    "        NameAdded=str(lagsPermitted)+\"Lags\"\n",
    "        pandaMTSCLags_test=pd.DataFrame([])\n",
    "\n",
    "        #obtaining all time series groups in train file\n",
    "        gr=pandaMTSC_train.groupby(pandaMTSC_train[pandaMTSC_train.columns[-1]])\n",
    "\n",
    "        for j in range(0,len(ts_indices)):\n",
    "\n",
    "            pandaOne_TS_train=gr.get_group(ts_indices[j])\n",
    "            pandaOne_TS_trainLags=pd.DataFrame([])\n",
    "            \n",
    "            #generating lags\n",
    "            for i in range(0,int(lagsPermitted)+1):\n",
    "                    pandaOne_TS_trainLags=pd.concat([pandaOne_TS_trainLags,\n",
    "                                                         pandaOne_TS_train[pandaOne_TS_train.columns[0:-2]].shift(i)],axis=1)\n",
    "            pandaOne_TS_trainLags=pd.concat([pandaOne_TS_trainLags,\n",
    "                                             pandaOne_TS_train[pandaOne_TS_train.columns[-2:]]],axis=1)\n",
    "\n",
    "            pandaMTSCLags_train=pd.concat([pandaMTSCLags_train,pandaOne_TS_trainLags],axis=0)\n",
    "\n",
    "        pandaMTSCLags_train=pandaMTSCLags_train.dropna()\n",
    "        pandaMTSCLags_train.columns=np.arange(pandaMTSCLags_train.shape[1])\n",
    "\n",
    "        pandaMTSCLags_train.to_csv('/Users/iulia/UCD laptop backup/UCD/mtsdata (2)/'+dirName+'/'+dirName+'_AllClassesTrain'+NameAdded+'.txt',\n",
    "                          header=None,\n",
    "                          sep='\\t',\n",
    "                          index=None)\n",
    "\n",
    "        ts_indicesTest=pandaMTSC_test[pandaMTSC_test.columns[-1]].unique()\n",
    "\n",
    "\n",
    "        pandaMTSC_test.shape[1]\n",
    "       # lagsPermitted=24/pandaMTSC_test[pandaMTSC_test.columns[0:-2]].shape[1]\n",
    "\n",
    "        gr=pandaMTSC_test.groupby(pandaMTSC_test[pandaMTSC_test.columns[-1]])\n",
    "        for j in range(0,len(ts_indicesTest)):\n",
    "\n",
    "            pandaOne_TS_test=gr.get_group(ts_indicesTest[j])\n",
    "            pandaOne_TS_testLags=pd.DataFrame([])\n",
    "            for i in range(0,int(lagsPermitted)+1):\n",
    "                    pandaOne_TS_testLags=pd.concat([pandaOne_TS_testLags,\n",
    "                                                             pandaOne_TS_test[pandaOne_TS_test.columns[0:-2]].shift(i)],axis=1)\n",
    "            pandaOne_TS_testLags=pd.concat([pandaOne_TS_testLags,\n",
    "                                                             pandaOne_TS_test[pandaOne_TS_test.columns[-2:]]],axis=1)\n",
    "            pandaMTSCLags_test=pd.concat([pandaMTSCLags_test,pandaOne_TS_testLags],axis=0)\n",
    "\n",
    "        pandaMTSCLags_test=pandaMTSCLags_test.dropna()\n",
    "        pandaMTSCLags_test.columns=np.arange(pandaMTSCLags_test.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        pandaMTSCLags_test.to_csv('/Users/iulia/UCD laptop backup/UCD/mtsdata (2)/'+dirName+'/'+dirName+'_AllClassesTest'+NameAdded+'.txt',\n",
    "                          header=None,\n",
    "                          sep='\\t',\n",
    "                          index=None)\n",
    "\n",
    "\n",
    "\n",
    "        classes=pandaMTSCLags_train[pandaMTSCLags_train.columns[-2]].unique()\n",
    "        Cl_group=pandaMTSCLags_train.groupby(pandaMTSCLags_train.columns[-2])\n",
    "       \n",
    "        #saving train test files by class flag\n",
    "\n",
    "        for i in range(0,len(classes)):\n",
    "            gr_cl=Cl_group.get_group(classes[i])\n",
    "            #shuffling samples over all time series and saving to X->Y format for CMAGEP regression  \n",
    "            gr_cl=gr_cl.sample(len(gr_cl))\n",
    "            Ytrain=pd.DataFrame(gr_cl[gr_cl.columns[target_index]])\n",
    "            Ytrain.to_csv('/Users/iulia/UCD laptop backup/UCD/mtsdata (2)/'+dirName+'/'+dirName+str(int(classes[i]))+'_YTrain'+NameAdded+'.txt',\n",
    "                          header=None,\n",
    "                          sep='\\t',\n",
    "                          index=None)\n",
    "            XTrain=gr_cl.drop([gr_cl.columns[target_index],gr_cl.columns[-1],gr_cl.columns[-2]],axis=1);\n",
    "            XTrain.to_csv('/Users/iulia/UCD laptop backup/UCD/mtsdata (2)/'+dirName+'/'+dirName+str(int(classes[i]))+'_XTrain'+NameAdded+'.txt',\n",
    "                          header=None,\n",
    "                          sep='\\t',\n",
    "                          index=None)\n",
    "\n",
    "    #saving problem specification and data transformations\n",
    "        f= open(\"/Users/iulia/UCD laptop backup/UCD/mtsdata (2)/\"+dirName+\"/problemSettings\"+NameAdded+\".txt\",\"a+\")\n",
    "        f.write(\"target feature %d\\r\\n\" % target_index)\n",
    "        f.write(\"original number of dimensions %d\\r\\n\" % len(importances))\n",
    "        f.write(\"final number of dimensions %d\\r\\n\" % int(pandaMTSCLags_train.shape[1]-2))\n",
    "        f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
